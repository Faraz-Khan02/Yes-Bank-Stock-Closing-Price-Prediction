{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "H0kj-8xxnORC",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faraz-Khan02/Yes-Bank-Stock-Closing-Price-Prediction/blob/main/Yes_Bank_Stock_Closing_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Yes Bank Stock Closing Price Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name -** Faraz Faisal Khan\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stock’s closing price of the month.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Capstone Project-2/data_YesBank_StockPrices.csv\")"
      ],
      "metadata": {
        "id": "XyLC-bm3o7CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset contains 185 rows and 5 columns"
      ],
      "metadata": {
        "id": "4uRheuTceP4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset contains zero null values\n"
      ],
      "metadata": {
        "id": "vHHPF_7YgAmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we've the Yes Bank Stock price dataset which has the monthly stock prices. It contains the following features in it, they are:\n",
        "\n",
        "**Date**: It denotes the month & year with respect to the price of the stock.\n",
        "\n",
        "**Open**: It denotes the opening price at which a stock started trading that month.\n",
        "\n",
        "**High**: It denotes the highest price at which a stock traded during a period.\n",
        "\n",
        "**Low**: It denotes the highest price at which a stock traded during a period.\n",
        "\n",
        "**Close**: It denotes the final trading price for that month.\n"
      ],
      "metadata": {
        "id": "Wcjc_yhAhOWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate = df.duplicated()\n",
        "print(duplicate.value_counts())"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no duplicate value in our dataset."
      ],
      "metadata": {
        "id": "eJweWE8CuDG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is zero null value in our dataset."
      ],
      "metadata": {
        "id": "Llkt9vbwu6y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.heatmap(df.isnull(), cbar=True, yticklabels=False)\n",
        "plt.xlabel(\"Column_name\", size=12, weight=\"bold\")\n",
        "plt.title(\"Missing values\",fontweight=\"bold\",size=15)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It shows zero missing value."
      ],
      "metadata": {
        "id": "JNd4z37TyeOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Data Cleaning***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copying data to preserve orignal dataset\n",
        "new_df = df.copy()"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here Date is not in regular format so we need to corvert it in 'YYYY-MM-DD' format."
      ],
      "metadata": {
        "id": "VjGjjziU-5Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['Date'] = new_df['Date'].apply(lambda x: datetime.strptime(x, \"%b-%y\"))"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "llbG3eNwAE17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we changed our Date format. Now we are ready to do EDA on our dataset."
      ],
      "metadata": {
        "id": "4lDkaqUFANR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Segregating the dataset into dependent & independent variable.\n",
        "X = new_df.drop(['Close','Date'],axis=1)       \n",
        "Y = new_df['Close']                          "
      ],
      "metadata": {
        "id": "-oETao_yTWFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here X is our Independent variable and Y is our Dependent variable."
      ],
      "metadata": {
        "id": "tJcduSD0Tg8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Exploratory Data Analysis***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Univariate Analysis**"
      ],
      "metadata": {
        "id": "-IOL9DxXbMTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Univariate Analysis we will analize our Dependent variable and Independent variable separately using different Displot and bar plot."
      ],
      "metadata": {
        "id": "Clg2pphyEaGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualisation of closing price with respect to dates.\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.xlabel('Year', fontsize=15)\n",
        "plt.ylabel('Closing Prices', fontsize=15)\n",
        "plt.plot(new_df['Date'], new_df['Close'],linewidth=2,color='red')\n",
        "plt.title('Closing Stock Prices along different Year', fontsize=20)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lcU8LN3kUORw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " After 2018 onwards the closing stock prices have witnessed a great downfall due to Rana Kapoor fraud case."
      ],
      "metadata": {
        "id": "dROx35uwXqh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Distplot for Dependent Variable - Close*"
      ],
      "metadata": {
        "id": "6F-Xcvfycr2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent variable-'Close'\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(df['Close'],color=\"g\")\n",
        "plt.xlabel('Closing Price',fontsize=20)\n",
        "plt.ylabel('Density',fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sASOFbX-bWWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can clearly see that distribution is right skewed so we have to do transformatiom to make it Normal using log transformation method.\n",
        "Log Transfomation is used when our data is highly skewed.\n",
        "\n"
      ],
      "metadata": {
        "id": "9CmxrmFrdtK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Collecting all our numeric column in a new variable \n",
        "numeric_features=new_df.describe().columns\n",
        "numeric_features\n",
        "     "
      ],
      "metadata": {
        "id": "EsogU-VCnfqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Mean and Median of Dependent Variable - Close*"
      ],
      "metadata": {
        "id": "20--P_RspAD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Mean and Median of our Dependent variable\n",
        "for col in numeric_features[-1:]:\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    ax = fig.gca()\n",
        "    feature = new_df[col]\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='red', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='green', linestyle='dashed', linewidth=2)    \n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nuOFQqAvnCEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here red dashed line shows Mean of our target variable and green dashed line shows Median of our target variable.\n",
        "\n",
        "Here there is lot of difference between our Mean and Median so we have to do Lof tranformation to reduce such a variance between our central tendency."
      ],
      "metadata": {
        "id": "LmGTQI3upzY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Applying Log Transformation on Dependent Variable - Close*"
      ],
      "metadata": {
        "id": "8NgOU8pUlmv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying log transformation on target variable \n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(np.log(df['Close']),color=\"g\")\n",
        "plt.xlabel('Closing Price',fontsize=20)\n",
        "plt.ylabel('Density',fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ENkQ122qjVKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can say that our data is transformed and it is normally distributed."
      ],
      "metadata": {
        "id": "_vQ82uUOq_4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Applying log transformation on target variable\n",
        "for col in numeric_features[-1:]:\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    ax = fig.gca()\n",
        "    feature = np.log(new_df[col])\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='red', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='green', linestyle='dashed', linewidth=2)    \n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Obnm8G9koeLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After doing Log transformation the difference between Mean and Median is reduced to a great extent."
      ],
      "metadata": {
        "id": "q3VFRzVck7i1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Distplot on Independent variable - (Open, High, Low)*"
      ],
      "metadata": {
        "id": "oZSje-L3l_qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distribution of independent variable\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(new_df['Open'], color='purple')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(new_df['High'], color='brown')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(new_df['Low'], color='magenta')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kfMjuO9yr-RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here just like our Dependent variable , all Independent variables are right skewed so, to convert it in normal distribution we need to do Log Transformation."
      ],
      "metadata": {
        "id": "f92U7kXT-Eaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Mean & Median of Independent Variables - (Open, High, Low)*"
      ],
      "metadata": {
        "id": "NnHaOG5c--YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting bar blot for each independent variables - (Open, High, Low)\n",
        "for col in numeric_features[:-1]:\n",
        "    fig = plt.figure(figsize=(12, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = new_df[col]\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='red', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='green', linestyle='dashed', linewidth=2)    \n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7bOoCgoB_Rxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here Red dashed line denotes Mean and Green dashed line denotes Median.\n",
        "\n",
        "From above graph we can see that there is much difference in between mean and median for all independent variable. It means independent variables are not normally distributed."
      ],
      "metadata": {
        "id": "nLwQIucbAKLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Applying Log Transformation on Independent Variables - (Open, High, Low)*"
      ],
      "metadata": {
        "id": "RwkxyzAiAzXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Applying log transformation independent variables.\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(np.log(new_df['Open']), color='purple')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(np.log(df['High']), color='brown')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(np.log(df['Low']), color='magenta')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vXKWteXsBLAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see after applying Log Transformation out Independent variables are Normally Distributed."
      ],
      "metadata": {
        "id": "atBcW2GNB4HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying log transformation on Independent Variables\n",
        "for col in numeric_features[:-1]:\n",
        "    fig = plt.figure(figsize=(12, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = np.log(new_df[col])\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='red', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='green', linestyle='dashed', linewidth=2)    \n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NqY3gQMzCgKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see after applying Log Transformation the difference between Mean & Median is almost finished."
      ],
      "metadata": {
        "id": "0csNsw9gDUfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bivariate Analysis**"
      ],
      "metadata": {
        "id": "fjzatvuWFkJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Bivariate Analysis we will see relation between Dependent and Independent Variables using scatter plot and heat map."
      ],
      "metadata": {
        "id": "IUDE0F0wFqSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Scatter plot for finding relation between Dependent & Independent variable*"
      ],
      "metadata": {
        "id": "20kji4f2G_7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using scatter plot\n",
        "for col in numeric_features[:-1]:\n",
        "  fig = plt.figure(figsize = (10,5))\n",
        "  ax = fig.gca()\n",
        "  features = new_df[col]\n",
        "  label = new_df['Close']\n",
        "  correlation = features.corr(label)\n",
        "  plt.scatter(x = features,y = label)\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('Close')\n",
        "  plt.title('Close Vs  ' + col + '_ correlation:' + str(correlation))\n",
        "  z = np.polyfit(df[col],df['Close'],1)\n",
        "  y_hat = np.poly1d(z)(df[col])\n",
        "  plt.plot(df[col] , y_hat, \"r--\",lw = 2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JZZXVECkHz9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above Scatter plot we can say all independent variables high correlation with our dependent variable.\n",
        "\n",
        "So, we cannot drop any column for modelling all the independent variables are important."
      ],
      "metadata": {
        "id": "nxRvH_4vIIie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Heatmap for checking correlation with Independent variables*"
      ],
      "metadata": {
        "id": "EwglMTh9JTkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Correlation heatmap\n",
        "plt.figure(figsize=(12,7))\n",
        "sns.heatmap(new_df.corr(),cmap='PiYG',annot=True)"
      ],
      "metadata": {
        "id": "IQwL15vgI5ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here dependent variable shows high correlation with all independent variables."
      ],
      "metadata": {
        "id": "OXX9Ex5JJnHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Checking Multicollinearity*"
      ],
      "metadata": {
        "id": "iU1RTaFPCZNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calculate_vif(X):\n",
        "\n",
        "  # calculating VIF\n",
        "  vif =pd.DataFrame()\n",
        "  vif[\"variables\"] = X.columns\n",
        "  vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X. shape[1])]\n",
        "\n",
        "  return(vif)\n",
        "\n",
        "calculate_vif(new_df[[i for i in new_df.describe().columns if i not in ['Date', 'Close']]])"
      ],
      "metadata": {
        "id": "lDyRS_GWF5Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here VIF of every independent variable is high so we cannot drop any of the columns."
      ],
      "metadata": {
        "id": "pZqgLLklHMB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Train Test Split*"
      ],
      "metadata": {
        "id": "hdeA8Q8JmjlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformation\n",
        "from scipy.stats import zscore\n",
        "X = X.apply(zscore)\n",
        "Y = np.log10(Y)"
      ],
      "metadata": {
        "id": "90ox9oLftXSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Trainig and Testing set of our dataset\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
        "print('Shape of X_train Set:',X_train.shape)\n",
        "print('Shape of X_test Set:',X_test.shape)\n",
        "print('Shape of Y_train Set:',Y_train.shape)\n",
        "print('Shape of Y_test Set:',Y_test.shape)"
      ],
      "metadata": {
        "id": "PyW3FSvylL1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here train_test_split() is used to split the dataset into training dataset and testing dataset.\n",
        "\n",
        "\n",
        "\n",
        "*   **Train dataset**: It is the dataset which is used in model building. Here it constitutes of 80% of the dataset.\n",
        "*   **Test dataset**: It is the dataset which is used to test our fit model.\n",
        "Here it constitutes 20% of the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "rLFZMiLfnnpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming data\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7rJkCD-BuQxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution."
      ],
      "metadata": {
        "id": "stRHJNdhvoNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "K5JZpau4qahT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables.Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between x (input) and y(output)."
      ],
      "metadata": {
        "id": "SOXxqyzWqkAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Linear Regression\n",
        "regressor=LinearRegression()\n",
        "regressor_model=regressor.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "Pk3xhtMHrTlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the training accuracy of model\n",
        "round(regressor.score(X_train,Y_train),4)"
      ],
      "metadata": {
        "id": "fuOngOAzrpVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, our model training accuracy is 80.91%."
      ],
      "metadata": {
        "id": "pYpSgcP5vvkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test accuracy of linear regression model\n",
        "round(regressor.score(X_test, Y_test), 4)"
      ],
      "metadata": {
        "id": "gwOHBb0Rv_X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, our model test accuracy is 82.83%."
      ],
      "metadata": {
        "id": "qaInKFqgwmMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction of test data\n",
        "Y_pred = regressor.predict(X_test)\n",
        "Y_pred"
      ],
      "metadata": {
        "id": "1-cFAWYIxSAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Y_test data into array\n",
        "np.array(Y_test)"
      ],
      "metadata": {
        "id": "PcFtnNbgx_qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the DataFrame of test and train Dataset\n",
        "train_Dataset = pd.DataFrame(X_train,Y_train)\n",
        "test_Dataset = pd.DataFrame(Y_test)\n",
        "test_Dataset.rename(columns= {'Close' :'Actual Closing Price'}, inplace =True)\n",
        "     "
      ],
      "metadata": {
        "id": "wxY8QjlN2Klr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual Closing Price VS Predicted closing Price\n",
        "test_Dataset['Predicted Closing Price']= Y_pred\n",
        "test_Dataset.head()"
      ],
      "metadata": {
        "id": "a6tA9cX22j3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Performance of Linear Regregression\n",
        "print(\"MSE :\", round(mean_squared_error(Y_test, Y_pred), 4))\n",
        "print(\"RMSE :\", round(math.sqrt(mean_squared_error(Y_test, Y_pred)), 4)) \n",
        "print(\"MAE :\", round(mean_absolute_error(Y_test, Y_pred), 4))\n",
        "print(\"MAPE :\", round(mean_absolute_percentage_error(Y_test, Y_pred), 4))\n",
        "print(\"r2 :\", round(r2_score(Y_test, Y_pred),4))"
      ],
      "metadata": {
        "id": "uiGG1CqL4aAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  **MSE** : The Mean Squared Error of an estimator measures the average of error squares i.e. the average squared difference between the estimated values and true value. It is a risk function, corresponding to the expected value of the squared error loss. It is always non – negative and values close to zero are better.\n",
        "*   **RMSE** :Root Mean Square Error is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.\n",
        "*   **MAE** : Mean Absolute Error calculates the average difference between the calculated values and actual values. It is also known as scale-dependent accuracy as it calculates error in observations taken on the same scale.\n",
        "*   **MAPE** : It measures accuracy of a forecast system. It measures this accuracy as a percentage, and can be calculated as the average absolute percent error for each time period minus actual values divided by actual values.\n",
        "*   **r2** : R-Squared is a statistical measure in a regression model that determines the proportion of variance in the dependent variable that can be explained by the independent variable.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DIkH4trt69X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Actual Price VS Predicted price for Linear Regression plot\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(10**(np.array(Y_test)),color='red')\n",
        "plt.plot(10**(Y_pred),color='green')\n",
        "plt.suptitle('Actual Price Vs Predicted Price', fontsize =18)\n",
        "plt.legend(['Actual', 'Predicted'], fontsize = 16)\n",
        "plt.xlabel('No. of Test Data', fontsize= 16)\n",
        "plt.ylabel('Closing Price', fontsize= 16)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "P2FYDkB0LeE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lasso Regression**"
      ],
      "metadata": {
        "id": "DUnWIl03ObAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word “LASSO” stands for Least Absolute Shrinkage and Selection Operator.\n",
        "\n",
        "Lasso regression is a regularization technique. It is used over regression methods for a more accurate prediction. This model uses shrinkage. Shrinkage is where data values are shrunk towards a central point as the mean."
      ],
      "metadata": {
        "id": "qEBoUMhAR68R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Lasso Regression\n",
        "lasso = Lasso(alpha=0.005, max_iter = 3000)\n",
        "lasso.fit(X_train, Y_train) "
      ],
      "metadata": {
        "id": "En5VmJhpR5uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy of Lasso regression model\n",
        "round(lasso.score(X_train, Y_train), 4)"
      ],
      "metadata": {
        "id": "E2J3fLEPToMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction of train data\n",
        "Y_pred_lasso = lasso.predict(X_test)\n",
        "Y_pred_lasso"
      ],
      "metadata": {
        "id": "hErI8jUPVSI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Y_test data into array\n",
        "np.array(Y_test)"
      ],
      "metadata": {
        "id": "-AGj7BMkVjBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Performance of lasso regression model\n",
        "\n",
        "print(\"MSE :\",round(mean_squared_error(Y_test, Y_pred_lasso), 4))\n",
        "print(\"RMSE :\",round(math.sqrt(mean_squared_error(Y_test, Y_pred_lasso)),4))\n",
        "print(\"MAE :\",round(mean_absolute_error(Y_test, Y_pred_lasso),4))\n",
        "print(\"MAPE :\",round(mean_absolute_percentage_error(Y_test, Y_pred_lasso),4))\n",
        "print(\"R2 :\",round(r2_score(Y_test, Y_pred_lasso), 4))"
      ],
      "metadata": {
        "id": "WSOQpXrQXDS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual price vs Predicted price for lasso regression ploting\n",
        "plt.figure(figsize= (12,5))\n",
        "plt.plot(10**(np.array(Y_test)),color='red')\n",
        "plt.plot(10**(Y_pred_lasso),color='green')\n",
        "plt.suptitle('Actual Price Vs Predicted Price', fontsize =18)\n",
        "plt.legend(['Predicted', 'Actual'], fontsize = 16)\n",
        "plt.xlabel('No of Test Data', fontsize= 16)\n",
        "plt.ylabel('Closing Price', fontsize = 16)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "EqahbgHmXSRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Cross Validation of Lasso***"
      ],
      "metadata": {
        "id": "7kVbWUsrhSxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation (CV) is one of the technique used to test the effectiveness of a machine learning models by dividing data into two segments, one used to learn or train a model and the other used to validate the model.If the model performs well over the test data and gives good accuracy, it means the model hasn’t overfitted the training data and can be used for prediction. It is also a re-sampling procedure used to evaluate a model if we have a limited data."
      ],
      "metadata": {
        "id": "mRbhKg-MhxM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameter of Tuning For Lasso Regression\n",
        "lasso_cv=Lasso()\n",
        "parameters={'alpha':[1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor=GridSearchCV(lasso_cv,parameters,scoring='neg_mean_squared_error',cv=3)\n",
        "lasso_regressor.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "sfxe6465hdBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding best parameter\n",
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"using \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "ySZ1e4AKioJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_lasso_pred1=lasso_regressor.predict(X_test)\n",
        "Y_lasso_pred1"
      ],
      "metadata": {
        "id": "jaX-IrDfjlik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test performance of Lasso after Cross-Validation\n",
        "print(\"MSE value is :\",round(mean_squared_error(Y_test, Y_lasso_pred1), 4))\n",
        "print(\"RMSE value is :\",round(math.sqrt(mean_squared_error(Y_test, Y_lasso_pred1)),4))\n",
        "print(\"MAE value is :\",round(mean_absolute_error(Y_test, Y_lasso_pred1),4))\n",
        "print(\"MAPE value is :\",round(mean_absolute_percentage_error(Y_test, Y_lasso_pred1),4))\n",
        "print(\"r2 score is :\",round(r2_score(Y_test, Y_lasso_pred1), 4))"
      ],
      "metadata": {
        "id": "uSqKctoYj1nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ridge Regression**"
      ],
      "metadata": {
        "id": "iJPcA5LGZO_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Regression is an adaptation of the popular and widely used linear regression algorithm. It enhances regular linear regression by slightly changing its cost function, which results in less overfit models."
      ],
      "metadata": {
        "id": "mxHpGAmrZeXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Ridge Regression\n",
        "ridge = Ridge (alpha= 0.1)\n",
        "ridge.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "OpSHzACVb61Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy of Ridge regression model\n",
        "round(ridge.score(X_train, Y_train), 4)"
      ],
      "metadata": {
        "id": "HfgfeZTWcTln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction of test data\n",
        "Y_pred_ridge = ridge.predict(X_test)\n",
        "Y_pred_ridge"
      ],
      "metadata": {
        "id": "rra5TJtQdue9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Y_test data into array\n",
        "np.array(Y_test)"
      ],
      "metadata": {
        "id": "rPv6bYlJeHZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}